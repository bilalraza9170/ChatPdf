[[["ab6cdb13-45c2-46a3-ae24-29ad082d3437",{"pageContent":"Below is the unedited penultimate draft of:\n[scanned in by OCR: contains errors]\nSearle, John. R. (1980) Minds, brains, and programs. Behavioral andBrain Sciences 3 (3): 417-457\nThis is the unedited penultimate draft of a BBS target article that has been accepted for publication \n(Copyright 1980: Cambridge University Press /-- publication date provisional) and is \ncurrently being circulated for Open Peer Commentary. This preprint is for inspection only, to help \nprospective commentators decide whether or not they wish to prepare a formal commentary. Please do \nnot prepare a commentary unless you have received the hard copy, invitation, instructions and deadline \ninformation.\nU.K.\nU.S.\nFor information on becoming a commentator on this or other BBS targetarticles, write to:\nbbs@soton.ac.uk\nFor information about subscribing or purchasing offprints of thepublished version, with commentaries \nand author's response, write to: (North America) or\n (All other countries).","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":1,"to":16}}}}],["2ab32053-d13d-4ad6-952c-076009f95ebb",{"pageContent":"bbs@soton.ac.uk\nFor information about subscribing or purchasing offprints of thepublished version, with commentaries \nand author's response, write to: (North America) or\n (All other countries).\njournals_subscriptions@cup.org\njournals_marketing@cup.cam.ac.uk\nMINDS, BRAINS, AND PROGRAMS\nJohn R. Searle\nDepartment of Philosophy\nUniversity of California\nBerkeley, California. 94720\nsearle@cogsci.berkeley.edu\nAbstract\nThis article can be viewed as an attempt to explore theconsequences of two propositions. (1) Intentionality in \nhumanbeings (and animals) is a product of causal features of the brain Iassume this is an empirical fact about \nthe actual causal relationsbetween mental processes and brains It says simply that certainbrain processes are \nsufficient for intentionality. (2)Instantiating a computer program is never by itself a sufficientcondition of \nintentionality The main argument of this paper isdirected at establishing this claim The form of the argument is to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":13,"to":30}}}}],["28ff6c49-8328-49cd-930a-ae94b69a8741",{"pageContent":"intentionality The main argument of this paper isdirected at establishing this claim The form of the argument is to\nshow how a human agent could instantiate the program and still nothave the relevant intentionality. These two \npropositions have thefollowing consequences (3) The explanation of how the brainproduces intentionality \ncannot be that it does it by instantiatinga computer program. This is a strict logical consequence of 1 and2. (4) \nAny mechanism capable of producing intentionality must havecausal powers equal to those of the brain. This is \nmeant to be atrivial consequence of 1. (5) Any attempt literally to createintentionality artificially (strong AI) \ncould not succeed just bydesigning programs but would have to duplicate the causal powers ofthe human \nbrain. This follows from 2 and 4.\n\"Could a machine think?\" On the argument advanced here only amachine could think, and only very special","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":30,"to":38}}}}],["a324024a-d4ca-4b51-8d55-bc05e58ccf98",{"pageContent":"brain. This follows from 2 and 4.\n\"Could a machine think?\" On the argument advanced here only amachine could think, and only very special \nkinds of machines,namely brains and machines with internal causal powers equivalentto those of brains And \nthat is why strong AI has little to tell usabout thinking, since it is not about machines but about programs,and \nno program by itself is sufficient for thinking.\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 1 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":37,"to":43}}}}],["4b3cf54e-24ff-408a-a6dd-4bc5b7c79bb3",{"pageContent":"Keywords\nartificial intelligence, brain, intentionality, mind\nWhat psychological and philosophical significance should we attach torecent efforts at computer simulations of \nhuman cognitive capacities?In answering this question, I find it useful to distinguish what I willcall \"strong\" AI \nfrom \"weak\" or \"cautious\" AI (ArtificialIntelligence). According to weak AI, the principal value of thecomputer \nin the study of the mind is that it gives us a very powerfultool. For example, it enables us to formulate and test \nhypotheses in amore rigorous and precise fashion. But according to strong AI, thecomputer is not merely a \ntool in the study of the mind; rather, theappropriately programmed computer really is a mind, in the sense that\ncomputers given the right programs can be literally said to understandand have other cognitive states. In strong \nAI, because the programmedcomputer has cognitive states, the programs are not mere tools thatenable us to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":1,"to":10}}}}],["47621017-966a-4dd7-a773-63b638ec65e6",{"pageContent":"AI, because the programmedcomputer has cognitive states, the programs are not mere tools thatenable us to \ntest psychological explanations; rather, the programs arethemselves the explanations.\nI have no objection to the claims of weak AI, at least as far as thisarticle is concerned. My discussion here will \nbe directed at the claimsI have defined as those of strong AI, specifically the claim that theappropriately \nprogrammed computer literally has cognitive states andthat the programs thereby explain human cognition. \nWhen I hereafterrefer to AI, I have in mind the strong version, as expressed by thesetwo claims.\nI will consider the work of Roger Schank and his colleagues at Yale(Schank & Abelson 1977), because I am \nmore familiar with it than I amwith any other similar claims, and because it provides a very clearexample of the \nsort of work I wish to examine. But nothing that followsdepends upon the details of Schank's programs. The","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":10,"to":18}}}}],["dda68bb6-20f7-4fb7-8008-48b2676f7a8a",{"pageContent":"sort of work I wish to examine. But nothing that followsdepends upon the details of Schank's programs. The \nsame arguments wouldapply to Winograd's SHRDLU (Winograd 1973), Weizenbaum's ELIZA(Weizenbaum \n1965), and indeed any Turing machine simulation of humanmental phenomena.\nVery briefly, and leaving out the various details, one can describeSchank's program as follows: the aim of the \nprogram is to simulate thehuman ability to understand stories. It is characteristic of humanbeings' story-\nunderstanding capacity that they can answer questionsabout the story even though the information that they \ngive was neverexplicitly stated in the story. Thus, for example, suppose you aregiven the following story:\n-A man went into a restaurant and ordered a hamburger. When thehamburger arrived it was burned to a crisp, \nand the man stormed out ofthe restaurant angrily, without paying for the hamburger or leaving atip.\" Now, if","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":18,"to":26}}}}],["da6b404c-0e92-4215-bce3-665a3d43539e",{"pageContent":"and the man stormed out ofthe restaurant angrily, without paying for the hamburger or leaving atip.\" Now, if \nyou are asked -Did the man eat the hamburger?\" you willpresumably answer, ' No, he did not.' Similarly, if \nyou are given thefollowing story: '-A man went into a restaurant and ordered ahamburger; when the \nhamburger came he was very pleased with it; and ashe left the restaurant he gave the waitress a large tip \nbefore payinghis bill,\" and you are asked the question, -Did the man eat thehamburger?,-' you will presumably \nanswer, -Yes, he ate the hamburger.\"Now Schank's machines can similarly answer questions about restaurants\nin this fashion. To do this, they have a -representation\" of the sortof information that human beings have about \nrestaurants, which enablesthem to answer such questions as those above, given these sorts ofstories. When the \nmachine is given the story and then asked thequestion, the machine will print out answers of the sort that we","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":26,"to":34}}}}],["ce47cbf3-6163-43c6-a567-1857f878a57c",{"pageContent":"machine is given the story and then asked thequestion, the machine will print out answers of the sort that we \nwouldexpect human beings to give if told similar stories. Partisans ofstrong AI claim that in this question and \nanswer sequence the machineis not only simulating a human ability but also\n1.that the machine can literally be said to understand the story andprovide the answers to questions, and\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 2 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":34,"to":39}}}}],["2a5b89fc-c8e8-414d-bfcb-76f9b14edcd8",{"pageContent":"2.that what the machine and its program do explains the human abilityto understand the story and answer \nquestions about it.\nBoth claims seem to me to be totally unsupported by Schank's' work, asI will attempt to show in what follows.\nOne way to test any theory of the mind is to ask oneself what it wouldbe like if my mind actually worked on \nthe principles that the theorysays all minds work on. Let us apply this test to the Schank programwith the \nfollowing Gedankenexperiment. Suppose that I'm locked in aroom and given a large batch of Chinese writing. \nSuppose furthermore(as is indeed the case) that I know no Chinese, either written orspoken, and that I'm not \neven confident that I could recognize Chinesewriting as Chinese writing distinct from, say, Japanese writing or\nmeaningless squiggles. To me, Chinese writing is just so manymeaningless squiggles. \nNow suppose further that after this first batch of Chinese writing I amgiven a second batch of Chinese script","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":1,"to":10}}}}],["7c8da1d6-785a-4706-a73e-b87753c47a55",{"pageContent":"meaningless squiggles. To me, Chinese writing is just so manymeaningless squiggles. \nNow suppose further that after this first batch of Chinese writing I amgiven a second batch of Chinese script \ntogether with a set of rules forcorrelating the second batch with the first batch. The rules are inEnglish, and I \nunderstand these rules as well as any other nativespeaker of English. They enable me to correlate one set of \nformalsymbols with another set of formal symbols, and all that 'formal' meanshere is that I can identify the \nsymbols entirely by their shapes. Nowsuppose also that I am given a third batch of Chinese symbols together\nwith some instructions, again in English, that enable me to correlateelements of this third batch with the first two \nbatches, and theserules instruct me how to give back certain Chinese symbols with certainsorts of shapes in \nresponse to certain sorts of shapes given me in thethird batch. Unknown to me, the people who are giving me","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":9,"to":17}}}}],["92ad219d-c506-416f-9718-b38beb655f5c",{"pageContent":"response to certain sorts of shapes given me in thethird batch. Unknown to me, the people who are giving me \nall of thesesymbols call the first batch \"a script,\" they call the second batch a\"story. ' and they call the third \nbatch \"questions.\" Furthermore, theycall the symbols I give them back in response to the third batch\"answers \nto the questions.\" and the set of rules in English that theygave me, they call \"the program.\"\nNow just to complicate the story a little, imagine that these peoplealso give me stories in English, which I \nunderstand, and they then askme questions in English about these stories, and I give them backanswers in \nEnglish. Suppose also that after a while I get so good atfollowing the instructions for manipulating the Chinese \nsymbols andthe programmers get so good at writing the programs that from theexternal point of view that is, \nfrom the point of view of somebodyoutside the room in which I am locked -- my answers to the questionsare","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":17,"to":25}}}}],["2c9a41a7-5456-48e9-b817-e015c9119f36",{"pageContent":"from the point of view of somebodyoutside the room in which I am locked -- my answers to the questionsare \nabsolutely indistinguishable from those of native Chinese speakers.Nobody just looking at my answers can tell \nthat I don't speak a word ofChinese.\nLet us also suppose that my answers to the English questions are, asthey no doubt would be, indistinguishable \nfrom those of other nativeEnglish speakers, for the simple reason that I am a native Englishspeaker. From the \nexternal point of view -- from the point of view ofsomeone reading my \"answers\" -- the answers to the \nChinese questions andthe English questions are equally good. But in the Chinese case, unlikethe English case, \nI produce the answers by manipulating uninterpretedformal symbols. As far as the Chinese is concerned, I \nsimply behavelike a computer; I perform computational operations on formallyspecified elements. For the \npurposes of the Chinese, I am simply aninstantiation of the computer program.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":25,"to":34}}}}],["672a729a-eafd-46f7-8e31-5be4034de844",{"pageContent":"simply behavelike a computer; I perform computational operations on formallyspecified elements. For the \npurposes of the Chinese, I am simply aninstantiation of the computer program.\nNow the claims made by strong AI are that the programmed computerunderstands the stories and that the \nprogram in some sense explainshuman understanding. But we are now in a position to examine theseclaims in \nlight of our thought experiment.\n1 As regards the first claim, it seems to me quite obvious in theexample that I do not understand a word of the \nChinese stories. I haveinputs and outputs that are indistinguishable from those of the nativeChinese speaker, \nand I can have any formal program you like, but Istill understand nothing. For the same reasons, Schank's \ncomputerunderstands nothing of any stories. whether in Chinese. English. orwhatever. since in the Chinese \ncase the computer is me. and in caseswhere the computer is not me, the computer has nothing more than I","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":33,"to":42}}}}],["f3338716-67d2-4b25-be68-c1b560942c77",{"pageContent":"case the computer is me. and in caseswhere the computer is not me, the computer has nothing more than I \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 3 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":42,"to":44}}}}],["5daa088d-28ef-42f9-84c5-1060ac0ec989",{"pageContent":"havein the case where I understand nothing.\n2. As regards the second claim, that the program explains humanunderstanding, we can see that the computer \nand its program do notprovide sufficient conditions of understanding since the computer andthe program are \nfunctioning, and there is no understanding. But does iteven provide a necessary condition or a significant \ncontribution tounderstanding? One of the claims made by the supporters of strong AI isthat when I understand \na story in English, what I am doing is exactlythe same -- or perhaps more of the same -- as what I was doing in\nmanipulating the Chinese symbols. It is simply more formal symbolmanipulation that distinguishes the case in \nEnglish, where I dounderstand, from the case in Chinese, where I don't. I have notdemonstrated that this \nclaim is false, but it would certainly appear anincredible claim in the example. Such plausibility as the claim has","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":1,"to":9}}}}],["b77f4bf3-7062-4a14-94bc-c1e3dc9a49ba",{"pageContent":"claim is false, but it would certainly appear anincredible claim in the example. Such plausibility as the claim has\nderives from the supposition that we can construct a program that willhave the same inputs and outputs as \nnative speakers, and in addition weassume that speakers have some level of description where they are also\ninstantiations of a program. \nOn the basis of these two assumptions we assume that even if Schank'sprogram isn't the whole story about \nunderstanding, it may be part ofthe story. Well, I suppose that is an empirical possibility, but notthe slightest \nreason has so far been given to believe that it is true,since what is suggested though certainly not demonstrated \n-- by theexample is that the computer program is simply irrelevant to myunderstanding of the story. In the \nChinese case I have everything thatartificial intelligence can put into me by way of a program, and Iunderstand","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":9,"to":17}}}}],["4d5546b1-104e-4261-8920-06fe0909c03a",{"pageContent":"Chinese case I have everything thatartificial intelligence can put into me by way of a program, and Iunderstand \nnothing; in the English case I understand everything, andthere is so far no reason at all to suppose that my \nunderstanding hasanything to do with computer programs, that is, with computationaloperations on purely \nformally specified elements. As long as theprogram is defined in terms of computational operations on purely\nformally defined elements, what the example suggests is that these bythemselves have no interesting connection \nwith understanding. They arecertainly not sufficient conditions, and not the slightest reason hasbeen given to \nsuppose that they are necessary conditions or even thatthey make a significant contribution to understanding.\nNotice that the force of the argument is not simply that differentmachines can have the same input and output \nwhile operating ondifferent formal principles -- that is not the point at all. Rather,whatever purely formal","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":17,"to":25}}}}],["28610a06-4a88-4016-af5a-1b955616cc3f",{"pageContent":"while operating ondifferent formal principles -- that is not the point at all. Rather,whatever purely formal \nprinciples you put into the computer, they willnot be sufficient for understanding, since a human will be able to\nfollow the formal principles without understanding anything. No reasonwhatever has been offered to suppose \nthat such principles are necessaryor even contributory, since no reason has been given to suppose thatwhen I \nunderstand English I am operating with any formal program atall.\nWell, then, what is it that I have in the case of the English sentencesthat I do not have in the case of the \nChinese sentences? The obviousanswer is that I know what the former mean, while I haven't thefaintest idea \nwhat the latter mean. But in what does this consist andwhy couldn't we give it to a machine, whatever it is? I \nwill return tothis question later, but first I want to continue with the example.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":25,"to":33}}}}],["5263e6e0-56f1-46b5-8477-93c274e218a2",{"pageContent":"what the latter mean. But in what does this consist andwhy couldn't we give it to a machine, whatever it is? I \nwill return tothis question later, but first I want to continue with the example.\nI have had the occasions to present this example to several workers inartificial intelligence, and, interestingly, \nthey do not seem to agreeon what the proper reply to it is. I get a surprising variety ofreplies, and in what \nfollows I will consider the most common of these(specified along with their geographic origins).\nBut first I want to block some common misunderstandings about\"understanding\": in many of these discussions \none finds a lot of fancyfootwork about the word \"understanding.\" My critics point out thatthere are many \ndifferent degrees of understanding; that \"understanding\"is not a simple two-place predicate; that there are even \ndifferent kindsand levels of understanding, and often the law of excluded middledoesn-t even apply in a","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":32,"to":40}}}}],["34bb5413-b87a-4ffa-976e-a75f42806c70",{"pageContent":"different kindsand levels of understanding, and often the law of excluded middledoesn-t even apply in a \nstraightforward way to statements of the form\"x understands y; that in many cases it is a matter for decision and\nnot a simple matter of fact whether x understands y; and so on. To allof these points I want to say: of course, of \ncourse. But they havenothing to do with the points at issue. There are clear cases in which\"understanding' \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 4 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":40,"to":45}}}}],["9eee4357-fa3b-4a14-a1da-e86f6dd5ce80",{"pageContent":"literally applies and clear cases in which it does notapply; and these two sorts of cases are all I need for this \nargument 2I understand stories in English; to a lesser degree I can understandstories in French; to a still lesser \ndegree, stories in German; and inChinese, not at all. My car and my adding machine, on the other hand,\nunderstand nothing: they are not in that line of business. We oftenattribute \"under standing\" and other cognitive \npredicates by metaphorand analogy to cars, adding machines, and other artifacts, but nothingis proved by such \nattributions. We say, \"The door knows when to openbecause of its photoelectric cell,\" \"The adding machine \nknows how)(understands how to, is able) to do addition and subtraction but notdivision,\" and \"The thermostat \nperceives chances in the temperature.\"\nThe reason we make these attributions is quite interesting, and it hasto do with the fact that in artifacts we","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":1,"to":9}}}}],["ede5c55d-59a1-44ee-a6e7-7b1d443fa09e",{"pageContent":"perceives chances in the temperature.\"\nThe reason we make these attributions is quite interesting, and it hasto do with the fact that in artifacts we \nextend our ownintentionality;3 our tools are extensions of our purposes, and so wefind it natural to make \nmetaphorical attributions of intentionality tothem; but I take it no philosophical ice is cut by such examples. The\nsense in which an automatic door \"understands instructions\" from itsphotoelectric cell is not at all the sense in \nwhich I understandEnglish. If the sense in which Schank's programmed computers understandstories is \nsupposed to be the metaphorical sense in which the doorunderstands, and not the sense in which I understand \nEnglish, the issuewould not be worth discussing. But Newell and Simon (1963) write thatthe kind of cognition \nthey claim for computers is exactly the same asfor human beings. I like the straightforwardness of this claim,","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":8,"to":16}}}}],["31102c9c-3273-4d81-b569-8056d38b4670",{"pageContent":"they claim for computers is exactly the same asfor human beings. I like the straightforwardness of this claim, \nand itis the sort of claim I will be considering. I will argue that in theliteral sense the programmed computer \nunderstands what the car and theadding machine understand, namely, exactly nothing. The computer\nunderstanding is not just (like my understanding of German) partial orincomplete; it is zero.\nNow to the replies:\nI. The systems reply (Berkeley). \"While it is true that the individualperson who is locked in the room does not \nunderstand the story, thefact is that he is merely part of a whole system, and the system doesunderstand the \nstory. The person has a large ledger in front of him inwhich are written the rules, he has a lot of scratch paper \nand pencilsfor doing calculations, he has 'data banks' of sets of Chinese symbols.Now, understanding is not \nbeing ascribed to the mere individual; ratherit is being ascribed to this whole system of which he is a part.\"","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":16,"to":25}}}}],["c4ab419c-371a-4788-904e-076c4aeffadd",{"pageContent":"being ascribed to the mere individual; ratherit is being ascribed to this whole system of which he is a part.\"\nMy response to the systems theory is quite simple: let the individualinternalize all of these elements of the \nsystem. He memorizes the rulesin the ledger and the data banks of Chinese symbols, and he does allthe \ncalculations in his head. The individual then incorporates theentire system. There isn't anything at all to the \nsystem that he doesnot encompass. We can even get rid of the room and suppose he worksoutdoors. All the \nsame, he understands nothing of the Chinese, and afortiori neither does the system, because there isn't anything \nin thesystem that isn't in him. If he doesn't understand, then there is noway the system could understand \nbecause the system is just a part ofhim.\nActually I feel somewhat embarrassed to give even this answer to thesystems theory because the theory seems","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":25,"to":33}}}}],["4728e367-42a1-4751-b211-f2b0c856e428",{"pageContent":"because the system is just a part ofhim.\nActually I feel somewhat embarrassed to give even this answer to thesystems theory because the theory seems \nto me so implausible to startwith. The idea is that while a person doesn't understand Chinese,somehow the \nconjunction of that person and bits of paper mightunderstand Chinese. It is not easy for me to imagine how \nsomeone whowas not in the grip of an ideology would find the idea at allplausible. Still, I think many people \nwho are committed to the ideologyof strong AI will in the end be inclined to say something very muchlike this; \nso let us pursue it a bit further. According to one versionof this view, while the man in the internalized systems \nexample doesn'tunderstand Chinese in the sense that a native Chinese speaker does(because, for example, he \ndoesn't know that the story refers torestaurants and hamburgers, etc.), still \"the man as a formal symbol","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":32,"to":40}}}}],["b20853db-d6fd-4a2c-bfa7-b9a2eb0391cf",{"pageContent":"doesn't know that the story refers torestaurants and hamburgers, etc.), still \"the man as a formal symbol\nmanipulation system\" really does understand Chinese. The subsystem ofthe man that is the formal symbol \nmanipulation system for Chineseshould not be confused with the subsystem for English.\nSo there are really two subsystems in the man; one understands English,the other Chinese, and \"it's just that the \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 5 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":40,"to":45}}}}],["040773c6-bd00-484e-b158-7f291faa135d",{"pageContent":"two systems have little todo with each other.\" But, I want to reply, not only do they have littleto do with each \nother, they are not even remotely alike. The subsystemthat understands English (assuming we allow ourselves \nto talk in thisjargon of \"subsystems\" for a moment) knows that the stories are aboutrestaurants and eating \nhamburgers, he knows that he is being askedquestions about restaurants and that he is answering questions as \nbesthe can by making various inferences from the content of the story, andso on. But the Chinese system \nknows none of this. Whereas the Englishsubsystem knows that \"hamburgers\" refers to hamburgers, the Chinese\nsubsystem knows only that \"squiggle squiggle\" is followed by \"squogglesquoggle.\" All he knows is that various \nformal symbols are beingintroduced at one end and manipulated according to rules written inEnglish, and other \nsymbols are going out at the other end.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":1,"to":9}}}}],["52c67943-895d-46e9-ae30-b15c7a14f041",{"pageContent":"formal symbols are beingintroduced at one end and manipulated according to rules written inEnglish, and other \nsymbols are going out at the other end. \nThe whole point of the original example was to argue that such symbolmanipulation by itself couldn't be \nsufficient for understanding Chinesein any literal sense because the man could write \"squoggle squoggle\"after \n\"squiggle squiggle\" without understanding anything in Chinese.And it doesn't meet that argument to postulate \nsubsystems within theman, because the subsystems are no better off than the man was in thefirst place; they \nstill don't have anything even remotely like what theEnglish-speaking man (or subsystem) has. Indeed, in the \ncase asdescribed, the Chinese subsystem is simply a part of the Englishsubsystem, a part that engages in \nmeaningless symbol manipulationaccording to rules in English.\nLet us ask ourselves what is supposed to motivate the systems reply inthe first place; that is, what independent","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":8,"to":17}}}}],["89957bb3-d95f-4230-bc6c-c8e71ce2e4dc",{"pageContent":"meaningless symbol manipulationaccording to rules in English.\nLet us ask ourselves what is supposed to motivate the systems reply inthe first place; that is, what independent \ngrounds are there supposedto be for saying that the agent must have a subsystem within him thatliterally \nunderstands stories in Chinese? As far as I can tell the onlygrounds are that in the example I have the same \ninput and output asnative Chinese speakers and a program that goes from one to the other.But the whole \npoint of the examples has been to try to show that thatcouldn't be sufficient for understanding, in the sense in \nwhich Iunderstand stories in English, because a person, and hence the set ofsystems that go to make up a \nperson, could have the right combinationof input, output, and program and still not understand anything in the\nrelevant literal sense in which I understand English. \nThe only motivation for saying there must be a subsystem in me thatunderstands Chinese is that I have a","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":16,"to":25}}}}],["778a0177-d913-4663-b9c4-ea3e1bfa77d3",{"pageContent":"relevant literal sense in which I understand English. \nThe only motivation for saying there must be a subsystem in me thatunderstands Chinese is that I have a \nprogram and I can pass the Turingtest; I can fool native Chinese speakers. But precisely one of thepoints at \nissue is the adequacy of the Turing test. The example showsthat there could be two \"systems,\" both of which \npass the Turing test,but only one of which understands; and it is no argument against thispoint to say that since \nthey both pass the Turing test they must bothunderstand, since this claim fails to meet the argument that the \nsystemin me that understands English has a great deal more than the systemthat merely processes Chinese. In \nshort, the systems reply simply begsthe question by insisting without argument that the system mustunderstand \nChinese.\nFurthermore, the systems reply would appear to lead to consequencesthat are independently absurd. If we are","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":24,"to":33}}}}],["9819da5f-3ad0-497d-861d-582fd96d3a0d",{"pageContent":"Chinese.\nFurthermore, the systems reply would appear to lead to consequencesthat are independently absurd. If we are \nto conclude that there must becognition in me on the grounds that I have a certain sort of input andoutput and a \nprogram in between, then it looks like all sorts ofnoncognitive subsystems are going to turn out to be cognitive. \nForexample, there is a level of description at which my stomach doesinformation processing, and it instantiates \nany number of computerprograms, but I take it we do not want to say that it has anyunderstanding [cf. \nPylyshyn: \"Computation and Cognition\" BBS 3(1)1980]. But if we accept the systems reply, then it is hard to \nsee howwe avoid saying that stomach, heart, liver, and so on, are allunderstanding subsystems, since there is \nno principled way todistinguish the motivation for saying the Chinese subsystem understandsfrom saying that \nthe stomach understands. It is, by the way, not ananswer to this point to say that the Chinese system has","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":32,"to":41}}}}],["f5b4b7d7-974f-48eb-a217-a09ef58f855e",{"pageContent":"the stomach understands. It is, by the way, not ananswer to this point to say that the Chinese system has \ninformation asinput and output and the stomach has food and food products as inputand output, since from the \npoint of view of the agent, from my point ofview, there is no information in either the food or the Chinese -- the\nChinese is just so many meaningless squiggles. The information in theChinese case is solely in the eyes of the \nprogrammers and theinterpreters, and there is nothing to prevent them from treating theinput and output of my \ndigestive organs as information if they sodesire.\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 6 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":41,"to":48}}}}],["35a4ffe2-6eca-4de8-bc8c-a980f1b96661",{"pageContent":"This last point bears on some independent problems in strong AI, and itis worth digressing for a moment to \nexplain it. If strong AI is to be abranch of psychology, then it must be able to distinguish those systemsthat are \ngenuinely mental from those that are not. It must be able todistinguish the principles on which the mind works \nfrom those on whichnonmental systems work; otherwise it will offer us no explanations ofwhat is specifically \nmental about the mental. And the mental-nonmentaldistinction cannot be just in the eye of the beholder but it \nmust beintrinsic to the systems; otherwise it would be up to any beholder totreat people as nonmental and, for \nexample, hurricanes as mental if helikes. But quite often in the AI literature the distinction is blurredin ways \nthat would in the long run prove disastrous to the claim thatAI is a cognitive inquiry. McCarthy, for example, \nwrites, '-Machines assimple as thermostats can be said to have beliefs, and having beliefsseems to be a","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":1,"to":9}}}}],["ed322b70-a2fc-414f-b684-758c53d079d5",{"pageContent":"writes, '-Machines assimple as thermostats can be said to have beliefs, and having beliefsseems to be a \ncharacteristic of most machines capable of problemsolving performance\" (McCarthy 1979). \nAnyone who thinks strong AI has a chance as a theory of the mind oughtto ponder the implications of that \nremark. We are asked to accept it asa discovery of strong AI that the hunk of metal on the wall that we useto \nregulate the temperature has beliefs in exactly the same sense thatwe, our spouses, and our children have \nbeliefs, and furthermore that\"most\" of the other machines in the room -- telephone, tape recorder,adding \nmachine, electric light switch, -- also have beliefs in thisliteral sense. It is not the aim of this article to argue \nagainstMcCarthy's point, so I will simply assert the following withoutargument. The study of the mind starts \nwith such facts as that humanshave beliefs, while thermostats, telephones, and adding machines don't.If you get","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":9,"to":17}}}}],["a84371ad-393c-49d0-9a6e-2f1af541678c",{"pageContent":"with such facts as that humanshave beliefs, while thermostats, telephones, and adding machines don't.If you get \na theory that denies this point you have produced acounterexample to the theory and the theory is false. \nOne gets the impression that people in AI who write this sort of thingthink they can get away with it because \nthey don't really take itseriously, and they don't think anyone else will either. I propose fora moment at least, to \ntake it seriously. Think hard for one minuteabout what would be necessary to establish that that hunk of metal \nonthe wall over there had real beliefs beliefs with direction of fit,propositional content, and conditions of \nsatisfaction; beliefs that hadthe possibility of being strong beliefs or weak beliefs; nervous,anxious, or secure \nbeliefs; dogmatic, rational, or superstitiousbeliefs; blind faiths or hesitant cogitations; any kind of beliefs. The","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":17,"to":24}}}}],["7d1c8bd2-d573-4b00-b0bd-c0579ae76f97",{"pageContent":"beliefs; dogmatic, rational, or superstitiousbeliefs; blind faiths or hesitant cogitations; any kind of beliefs. The\nthermostat is not a candidate. Neither is stomach, liver addingmachine, or telephone. However, since we are \ntaking the idea seriously,notice that its truth would be fatal to strong AI's claim to be ascience of the mind. For \nnow the mind is everywhere. What we wanted toknow is what distinguishes the mind from thermostats and \nlivers. And ifMcCarthy were right, strong AI wouldn't have a hope of telling usthat.\nII. The Robot Reply (Yale). \"Suppose we wrote a different kind ofprogram from Schank's program. Suppose \nwe put a computer inside arobot, and this computer would not just take in formal symbols as inputand give out \nformal symbols as output, but rather would actuallyoperate the robot in such a way that the robot does \nsomething very muchlike perceiving, walking, moving about, hammering nails, eatingdrinking -- anything you","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":24,"to":32}}}}],["4ddc14ea-3fca-4e7f-9cef-d8e551a75eb2",{"pageContent":"something very muchlike perceiving, walking, moving about, hammering nails, eatingdrinking -- anything you \nlike. The robot would, for example have atelevision camera attached to it that enabled it to 'see,' it wouldhave \narms and legs that enabled it to 'act,' and all of this would becontrolled by its computer 'brain.' Such a robot \nwould, unlike Schank'scomputer, have genuine understanding and other mental states.\"\nThe first thing to notice about the robot reply is that it tacitlyconcedes that cognition is not solely a matter of \nformal symbolmanipulation, since this reply adds a set of causal relation with theoutside world [cf. Fodor: \n\"Methodological Solipsism\" BBS 3(1) 1980].But the answer to the robot reply is that the addition of such\n\"perceptual\" and \"motor\" capacities adds nothing by way ofunderstanding, in particular, or intentionality, in \ngeneral, toSchank's original program. To see this, notice that the same thoughtexperiment applies to the robot","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":32,"to":40}}}}],["8b3b96f2-5647-47f0-b193-70c9c9b5b4c4",{"pageContent":"general, toSchank's original program. To see this, notice that the same thoughtexperiment applies to the robot \ncase. Suppose that instead of thecomputer inside the robot, you put me inside the room and, as in theoriginal \nChinese case, you give me more Chinese symbols with moreinstructions in English for matching Chinese \nsymbols to Chinese symbolsand feeding back Chinese symbols to the outside. Suppose, unknown tome, some \nof the Chinese symbols that come to me come from a televisioncamera attached to the robot and other \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 7 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":40,"to":46}}}}],["08741ba6-8dba-41be-8110-94452e26c0b3",{"pageContent":"Chinese symbols that I am givingout serve to make the motors inside the robot move the robot's legs orarms. \nIt is important to emphasize that all I am doing is manipulatingformal symbols: I know none of these other facts. \nI am receiving\"information\" from the robot's \"perceptual\" apparatus, and I am givingout \"instructions\" to its \nmotor apparatus without knowing either ofthese facts. I am the robot's homunculus, but unlike the traditional\nhomunculus, I don't know what's going on. I don't understand anythingexcept the rules for symbol \nmanipulation. Now in this case I want tosay that the robot has no intentional states at all; it is simplymoving \nabout as a result of its electrical wiring and its program. Andfurthermore, by instantiating the program I have no \nintentional statesof the relevant type. All I do is follow formal instructions aboutmanipulating formal symbols.\nIII. The brain simulator reply (Berkeley and M.I.T.). \"Suppose wedesign a program that doesn't represent","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":1,"to":9}}}}],["2c0cb67c-2b12-4cdd-9256-5433e9177f78",{"pageContent":"III. The brain simulator reply (Berkeley and M.I.T.). \"Suppose wedesign a program that doesn't represent \ninformation that we have aboutthe world, such as the information in Schank's scripts, but simulatesthe actual \nsequence of neuron firings at the synapses of the brain of anative Chinese speaker when he understands stories \nin Chinese and givesanswers to them. The machine takes in Chinese stories andquestions about them as input, \nit simulates the formal l structure ofactual Chinese brains in processing these stories, and it gives outChinese \nanswers as outputs. We can even imagine that the machineoperates, not with a single serial program, but with a \nwhole set ofprograms operating in parallel, in the manner that actual human brainspresumably operate when \nthey process natural language. Now surely insuch a case we would have to say that the machine understood \nthestories; and if we refuse to say that, wouldn't we also have to denythat native Chinese speakers understood","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":9,"to":17}}}}],["918d5d8a-d3ac-4c1b-82a5-db6b3b4cfcf2",{"pageContent":"thestories; and if we refuse to say that, wouldn't we also have to denythat native Chinese speakers understood \nthe stories? At the level ofthe synapses, what would or could be different about the program of thecomputer \nand the program of the Chinese brain?\"\nBefore countering this reply I want to digress to note that it is anodd reply for any partisan of artificial \nintelligence (orfunctionalism, etc.) to make: I thought the whole idea ofstrong AI is that we don't need to know \nhow the brain works to know howthe mind works. The basic hypothesis, or so I had supposed, was thatthere \nis a level of mental operations consisting of computationalprocesses over formal elements that constitute the \nessence of themental and can be realized in all sorts of different brain processes,in the same way that any \ncomputer program can be realized in differentcomputer hardwares: on the assumptions of strong AI, the mind","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":17,"to":25}}}}],["812917fe-21e6-4ed2-aa53-476db0922377",{"pageContent":"computer program can be realized in differentcomputer hardwares: on the assumptions of strong AI, the mind \nis to thebrain as the program is to the hardware, and thus we can understand themind without doing \nneurophysiology. If we had to know how the brainworked to do AI, we wouldn't bother with AI. However, \neven getting thisclose to the operation of the brain is still not sufficient to produceunderstanding. To see this, \nimagine that instead of a mono lingual manin a room shuffling symbols we have the man operate an elaborate \nset ofwater pipes with valves connecting them. When the man receives theChinese symbols, he looks up in the \nprogram, written in English, whichvalves he has to turn on and off. Each water connection corresponds toa \nsynapse in the Chinese brain, and the whole system is rigged up sothat after doing all the right firings, that is \nafter turning on allthe right faucets, the Chinese answers pop out at the output end of theseries of pipes.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":25,"to":33}}}}],["137ee5f4-ba4c-4d25-ad74-b0dde8e02fad",{"pageContent":"after turning on allthe right faucets, the Chinese answers pop out at the output end of theseries of pipes.\nI Now where is the understanding in this system? It takes Chinese asinput, it simulates the formal structure of \nthe synapses of the Chinesebrain, and it gives Chinese as output. But the man certainly doesn-tunderstand \nChinese, and neither do the water pipes, and if we aretempted to adopt what I think is the absurd view that \nsomehow theconjunction of man and water pipes understands, remember that inprinciple the man can \ninternalize the formal structure of the waterpipes and do all the \"neuron firings\" in his imagination. The problem\nwith the brain simulator is that it is simulating the wrong thingsabout the brain. As long as it simulates only the \nformal structure ofthe sequence of neuron firings at the synapses, it won't have simulatedwhat matters about \nthe brain, namely its causal properties, its abilityto produce intentional states. And that the formal properties are","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":33,"to":41}}}}],["a6a7b3e1-200d-46f0-8d8d-edf29f5408ed",{"pageContent":"the brain, namely its causal properties, its abilityto produce intentional states. And that the formal properties are \nnotsufficient for the causal properties is shown by the water pipeexample: we can have all the formal \nproperties carved off from therelevant neurobiological causal properties.\nIV. The combination reply (Berkeley and Stanford). 'While each of theprevious three replies might not be \ncompletely convincing by itself asa refutation of the Chinese room counterexample, if you take all threetogether \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 8 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":41,"to":47}}}}],["d73827b4-6a2a-4c30-b77b-3d195aaa4539",{"pageContent":"they are collectively much more convincing and even decisive.Imagine a robot with a brain-shaped computer \nlodged in its cranialcavity, imagine the computer programmed with all the synapses of ahuman brain, imagine \nthe whole behavior of the robot isindistinguishable from human behavior, and now think of the whole thingas a \nunified system and not just as a computer with inputs and outputs.Surely in such a case we would have to \nascribe intentionality to thesystem. '\nI entirely agree that in such a case we would find it rational andindeed irresistible to accept the hypothesis that \nthe robot hadintentionality, as long as we knew nothing more about it. Indeed,besides appearance and \nbehavior, the other elements of the combinationare really irrelevant. If we could build a robot whose behavior \nwasindistinguishable over a large range from human behavior, we wouldattribute intentionality to it, pending","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":1,"to":9}}}}],["5af78d11-3f5b-4a27-b7bc-2e00d2c8e75c",{"pageContent":"wasindistinguishable over a large range from human behavior, we wouldattribute intentionality to it, pending \nsome reason not to. We wouldn'tneed to know in advance that its computer brain was a formal analogueof the \nhuman brain.\nBut I really don't see that this is any help to the claims of strongAI; and here-s why: According to strong AI, \ninstantiating a formalprogram with the right input and output is a sufficient condition of,indeed is constitutive of, \nintentionality. As Newell (1979) puts it,the essence of the mental is the operation of a physical symbol system.\nBut the attributions of intentionality that we make to the robot inthis example have nothing to do with formal \nprograms. They are simplybased on the assumption that if the robot looks and behavessufficiently like us, then \nwe would suppose, until proven otherwise,that it must have mental states like ours that cause and are","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":9,"to":17}}}}],["ad9b1517-52a1-4780-a4d3-4d18cd8adef8",{"pageContent":"we would suppose, until proven otherwise,that it must have mental states like ours that cause and are \nexpressedby its behavior and it must have an inner mechanism capable ofproducing such mental states. If we \nknew independently how to accountfor its behavior without such assumptions we would not attribute\nintentionality to it especially if we knew it had a formal program. Andthis is precisely the point of my earlier \nreply to objection 11.\nSuppose we knew that the robot's behavior was entirely accounted for bythe fact that a man inside it was \nreceiving uninterpreted formalsymbols from the robot's sensory receptors and sending outuninterpreted formal \nsymbols to its motor mechanisms, and the man wasdoing this symbol manipulation in accordance with a bunch \nof rules.Furthermore, suppose the man knows none of these facts about the robot,all he knows is which \noperations to perform on which meaninglesssymbols. In such a case we would regard the robot as an ingenious","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":17,"to":26}}}}],["9955b27b-fab0-49d4-bca5-e7593eebc235",{"pageContent":"operations to perform on which meaninglesssymbols. In such a case we would regard the robot as an ingenious\nmechanical dummy. The hypothesis that the dummy has a mind would nowbe unwarranted and unnecessary, \nfor there is now no longer any reasonto ascribe intentionality to the robot or to the system of which it isa part \n(except of course for the man's intentionality in manipulatingthe symbols). The formal symbol manipulations go \non, the input andoutput are correctly matched, but the only real locus of intentionalityis the man, and he doesn't \nknow any of the relevant intentional states;he doesn't, for example, see what comes into the robot's eyes, he\ndoesn't intend to move the robot's arm, and he doesn't understand anyof the remarks made to or by the robot. \nNor, for the reasons statedearlier, does the system of which man and robot are a part.\nTo see this point, contrast this case with cases in which we find itcompletely natural to ascribe intentionality to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":26,"to":34}}}}],["7d6abb4c-769c-4ac4-a674-acc96719e175",{"pageContent":"To see this point, contrast this case with cases in which we find itcompletely natural to ascribe intentionality to \nmembers of certainother primate species such as apes and monkeys and to domestic animalssuch as dogs. The \nreasons we find it natural are, roughly, two: wecan't make sense of the animal's behavior without the ascription \nofintentionality and we can see that the beasts are made of similar stuffto ourselves -- that is an eye, that a \nnose, this is its skin, and soon. Given the coherence of the animal's behavior and the assumption ofthe same \ncausal stuff underlying it, we assume both that the animalmust have mental states underlying its behavior, and \nthat the mentalstates must be produced by mechanisms made out of the stuff that islike our stuff. We would \ncertainly make similar assumptions about therobot unless we had some reason not to, but as soon as we knew \nthat thebehavior was the result of a formal program, and that the actual causalproperties of the physical","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":34,"to":42}}}}],["6262b839-0392-43a4-b4d5-7d26ec9516f1",{"pageContent":"that thebehavior was the result of a formal program, and that the actual causalproperties of the physical \nsubstance were irrelevant we would abandonthe assumption of intentionality. [See \"Cognition and \nConsciousness inNonhuman Species BBS 1(4) 1978.]\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 9 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":42,"to":46}}}}],["639b6870-2fc3-4840-a9d8-2db3e0395335",{"pageContent":"There are two other responses to my example that come up frequently(and so are worth discussing) but really \nmiss the point.\nV. The other minds reply (Yale). \"How do you know that other peopleunderstand Chinese or anything else? \nOnly by their behavior. Now thecomputer can pass the behavioral tests as well as they can (inprinciple), so if \nyou are going to attribute cognition to other peopleyou must in principle also attribute it to computers. '\nThis objection really is only worth a short reply. The problem in thisdiscussion is not about how I know that \nother people have cognitivestates, but rather what it is that I am attributing to them when Iattribute cognitive \nstates to them. The thrust of the argument is thatit couldn't be just computational processes and their output \nbecausethe computational processes and their output can exist without thecognitive state. It is no answer to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":1,"to":9}}}}],["a7c0624e-72dd-48e5-b54f-d829604c5308",{"pageContent":"becausethe computational processes and their output can exist without thecognitive state. It is no answer to \nthis argument to feign anesthesia.In 'cognitive sciences\" one presupposes the reality and knowability ofthe \nmental in the same way that in physical sciences one has topresuppose the reality and knowability of physical \nobjects.\nVI. The many mansions reply (Berkeley). \"Your whole argumentpresupposes that AI is only about analogue \nand digital computers. Butthat just happens to be the present state of technology. Whatever thesecausal \nprocesses are that you say are essential for intentionality(assuming you are right), eventually we will be able to \nbuild devicesthat have these causal processes, and that will be artificialintelligence. So your arguments are in \nno way directed at the abilityof artificial intelligence to produce and explain cognition.\"\nI really have no objection to this reply save to say that it in effecttrivializes the project of strong AI by","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":9,"to":18}}}}],["a7b03d5c-bbca-408f-8f0a-db8c357c3bef",{"pageContent":"I really have no objection to this reply save to say that it in effecttrivializes the project of strong AI by \nredefining it as whateverartificially produces and explains cognition. The interest of theoriginal claim made on \nbehalf of artificial intelligence is that it wasa precise, well defined thesis: mental processes are computational\nprocesses over formally defined elements. I have been concerned tochallenge that thesis. If the claim is \nredefined so that it is nolonger that thesis, my objections no longer apply because there is nolonger a testable \nhypothesis for them to apply to.\nLet us now return to the question I promised I would try to answer:granted that in my original example I \nunderstand the English and I donot understand the Chinese, and granted therefore that the machinedoesn't \nunderstand either English or Chinese, still there must besomething about me that makes it the case that I","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":18,"to":26}}}}],["dc2194c9-0555-41f6-bc4f-5d53c23f083e",{"pageContent":"understand either English or Chinese, still there must besomething about me that makes it the case that I \nunderstand English anda corresponding something lacking in me that makes it the case that Ifail to understand \nChinese. Now why couldn't we give those somethings,whatever they are, to a machine?\nI see no reason in principle why we couldn't give a machine thecapacity to understand English or Chinese, \nsince in an important senseour bodies with our brains are precisely such machines. But I do seevery strong \narguments for saying that we could not give such a thing toa machine where the operation of the machine is \ndefined solely in termsof computational processes over formally defined elements; that is,where the operation \nof the machine is defined as an instantiation of acomputer program. It is not because I am the instantiation of a\ncomputer program that I am able to understand English and have otherforms of intentionality (I am, I suppose,","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":26,"to":34}}}}],["64de6418-20a8-4ecd-9522-0a033b9cc9c1",{"pageContent":"computer program that I am able to understand English and have otherforms of intentionality (I am, I suppose, \nthe instantiation of anynumber of computer programs), but as far as we know it is because I ama certain sort \nof organism with a certain biological (i.e. chemical andphysical) structure, and this structure, under certain \nconditions, iscausally capable of producing perception, action, understanding,learning, and other intentional \nphenomena. And part of the point of thepresent argument is that only something that had those causal powers\ncould have that intentionality. Perhaps other physical and chemicalprocesses could produce exactly these \neffects; perhaps, for example,Martians also have intentionality but their brains are made ofdifferent stuff. That \nis an empirical question, rather like thequestion whether photosynthesis can be done by something with a\nchemistry different from that of chlorophyll.\n7/14/03 6:14 PMMinds, Brains, and Programs","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":34,"to":43}}}}],["486b1f9f-9a85-437b-a720-c80e3baeb61f",{"pageContent":"is an empirical question, rather like thequestion whether photosynthesis can be done by something with a\nchemistry different from that of chlorophyll.\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 10 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":41,"to":44}}}}],["1de32464-8408-43fb-964a-dc6882391744",{"pageContent":"But the main point of the present argument is that no purely formalmodel will ever be sufficient by itself for \nintentionality because theformal properties are not by themselves constitutive of intentionality,and they have by \nthemselves no causal powers except the power, wheninstantiated, to produce the next stage of the formalism \nwhen themachine is running. And any other causal properties that particularrealizations of the formal model \nhave, are irrelevant to the formalmodel because we can always put the same formal model in a different\nrealization where those causal properties are obviously absent. Evenif, by some miracle Chinese speakers \nexactly realize Schank's program,we can put the same program in English speakers, water pipes, or\ncomputers, none of which understand Chinese, the programnotwithstanding.\nWhat matters about brain operations is not the formal shadow cast bythe sequence of synapses but rather the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":1,"to":9}}}}],["57584fc1-d11b-4502-938d-7e669fe6025f",{"pageContent":"computers, none of which understand Chinese, the programnotwithstanding.\nWhat matters about brain operations is not the formal shadow cast bythe sequence of synapses but rather the \nactual properties of thesequences. All the arguments for the strong version of artificialintelligence that I have \nseen insist on drawing an outline around theshadows cast by cognition and then claiming that the shadows are \nthereal thing. By way of concluding I want to try to state some of thegeneral philosophical points implicit in the \nargument. For clarity Iwill try to do it in a question and answer fashion, and I begin withthat old chestnut of a \nquestion:\n\"Could a machine think?\"\nThe answer is, obviously, yes. We are precisely such machines.\n\"Yes, but could an artifact, a man-made machine think?\"\nAssuming it is possible to produce artificially a machine with anervous system, neurons with axons and","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":8,"to":18}}}}],["cfc2b879-29bc-4ac4-a857-fe3b0ca35b3d",{"pageContent":"\"Yes, but could an artifact, a man-made machine think?\"\nAssuming it is possible to produce artificially a machine with anervous system, neurons with axons and \ndendrites, and all the rest ofit, sufficiently like ours, again the answer to the question seems tobe obviously, yes. \nIf you can exactly duplicate the causes, you couldduplicate the effects. And indeed it might be possible to \nproduceconsciousness, intentionality, and all the rest of it using some othersorts of chemical principles than \nthose that human beings use. It is,as I said, an empirical question. \"OK, but could a digital computerthink?\"\nIf by \"digital computer\" we mean anything at all that has a level ofdescription where it can correctly be \ndescribed as the instantiation ofa computer program, then again the answer is, of course, yes, since weare the \ninstantiations of any number of computer programs, and we canthink.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":17,"to":25}}}}],["e1c32849-fe62-4a58-8121-f5fdab3f45a0",{"pageContent":"described as the instantiation ofa computer program, then again the answer is, of course, yes, since weare the \ninstantiations of any number of computer programs, and we canthink.\n\"But could something think, understand, and so on solely in virtue ofbeing a computer with the right sort of \nprogram? Could instantiating aprogram, the right program of course, by itself be a sufficientcondition of \nunderstanding?\"\nThis I think is the right question to ask, though it is usuallyconfused with one or more of the earlier questions, \nand the answer toit is no.\n\"Why not?\"\nBecause the formal symbol manipulations by themselves don't have anyintentionality; they are quite \nmeaningless; they aren't even symbolmanipulations, since the symbols don't symbolize anything. In thelinguistic \njargon, they have only a syntax but no semantics. Suchintentionality as computers appear to have is solely in \nthe minds ofthose who program them and those who use them, those who send in theinput and those who","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":24,"to":35}}}}],["56540f53-8bef-404e-8ab3-61d6b173747b",{"pageContent":"the minds ofthose who program them and those who use them, those who send in theinput and those who \ninterpret the output.\nThe aim of the Chinese room example was to try to show this by showingthat as soon as we put something \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 11 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":35,"to":39}}}}],["0b2e9624-3e25-440d-8437-b2b2b9bd0db2",{"pageContent":"into the system that really does haveintentionality (a man), and we program him with the formal program, you\ncan see that the formal program carries no additional intentionality.It adds nothing, for example, to a man's \nability to understandChinese.\nPrecisely that feature of AI that seemed so appealing -- the distinctionbetween the program and the realization \n-- proves fatal to the claimthat simulation could be duplication. The distinction between theprogram and its \nrealization in the hardware seems to be parallel to thedistinction between the level of mental operations and the \nlevel ofbrain operations. And if we could describe the level of mentaloperations as a formal program, then it \nseems we could describe whatwas essential about the mind without doing either introspectivepsychology or \nneurophysiology of the brain. But the equation, \"mind isto brain as program is to hardware\" breaks down at \nseveral pointsamong them the following three:","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":1,"to":10}}}}],["6d41fbed-77f8-4245-ba3f-d24d883ca66f",{"pageContent":"neurophysiology of the brain. But the equation, \"mind isto brain as program is to hardware\" breaks down at \nseveral pointsamong them the following three:\nFirst, the distinction between program and realization has theconsequence that the same program could have \nall sorts of crazyrealizations that had no form of intentionality. Weizenbaum (1976, Ch.2), for example, shows \nin detail how to construct a computer using aroll of toilet paper and a pile of small stones. Similarly, the Chinese\nstory understanding program can be programmed into a sequence of waterpipes, a set of wind machines, or a \nmonolingual English speaker, noneof which thereby acquires an understanding of Chinese. Stones, toiletpaper, \nwind, and water pipes are the wrong kind of stuff to haveintentionality in the first place -- only something that \nhas the samecausal powers as brains can have intentionality -- and though theEnglish speaker has the right","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":9,"to":17}}}}],["9a0c0292-b8ee-4c65-ab52-3c33d99e26e7",{"pageContent":"has the samecausal powers as brains can have intentionality -- and though theEnglish speaker has the right \nkind of stuff for intentionality you caneasily see that he doesn't get any extra intentionality by memorizingthe \nprogram, since memorizing it won't teach him Chinese.\nSecond, the program is purely formal, but the intentional states arenot in that way formal. They are defined in \nterms of their content, nottheir form. The belief that it is raining, for example, is not definedas a certain formal \nshape, but as a certain mental content withconditions of satisfaction, a direction of fit (see Searle 1979), andthe \nlike. Indeed the belief as such hasn't even got a formal shape inthis syntactic sense, since one and the same \nbelief can be given anindefinite number of different syntactic expressions in differentlinguistic systems.\nThird, as I mentioned before, mental states and events are literally aproduct of the operation of the brain, but","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":17,"to":25}}}}],["863332ac-7593-4614-b5ae-8f755e16d3de",{"pageContent":"Third, as I mentioned before, mental states and events are literally aproduct of the operation of the brain, but \nthe program is not in thatway a product of the computer.\n-Well if programs are in no way constitutive of mental processes, whyhave so many people believed the \nconverse? That at least needs someexplanation.\"\nI don't really know the answer to that one. The idea that computersimulations could be the real thing ought to \nhave seemed suspicious inthe first place because the computer isn't confined to simulatingmental operations, by \nany means. No one supposes that computersimulations of a five-alarm fire will burn the neighborhood down or\nthat a computer simulation of a rainstorm will leave us all drenched.Why on earth would anyone suppose that a \ncomputer simulation ofunderstanding actually understood anything? It is sometimes said thatit would be \nfrightfully hard to get computers to feel pain or fall inlove, but love and pain are neither harder nor easier than","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":25,"to":34}}}}],["587b37b9-c51b-4229-84da-931479c08953",{"pageContent":"frightfully hard to get computers to feel pain or fall inlove, but love and pain are neither harder nor easier than \ncognition oranything else. For simulation, all you need is the right input andoutput and a program in the middle \nthat transforms the former into thelatter. That is all the computer has for anything it does. To confusesimulation \nwith duplication is the same mistake, whether it is pain,love, cognition, fires, or rainstorms.\nStill, there are several reasons why AI must have seemed and to manypeople perhaps still does seem -- in \nsome way to reproduce and therebyexplain mental phenomena, and I believe.we will not succeed in removing\nthese illusions until we have fully exposed the reasons that give riseto them.\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 12 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":34,"to":42}}}}],["e748e369-0b84-4ff6-a728-b1ede0b41ef8",{"pageContent":"First, and perhaps most important, is a confusion about the notion ofinformation processing: many people in \ncognitive science believe thatthe human brain, with its mind, does something called -informationprocessing,\" \nand analogously the computer with its program doesinformation processing; but fires and rainstorms, on the \nother hand,don't do information processing at all. Thus, though the computer cansimulate the formal features \nof any process whatever, it stands in aspecial relation to the mind and brain because when the computer is\nproperly programmed, ideally with the same program as the brain, theinformation processing is identical in the \ntwo cases, and thisinformation processing is really the essence of the mental. \nBut the trouble with this argument is that it rests on an ambiguity inthe notion of '- information.\" In the sense in \nwhich people \"processinformation\" when they reflect, say, on problems in arithmetic or whenthey read and","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":1,"to":9}}}}],["845877d4-9c83-4d36-be81-cb774f268879",{"pageContent":"which people \"processinformation\" when they reflect, say, on problems in arithmetic or whenthey read and \nanswer questions about stories, the programmed computerdoes not do -information processing.\" Rather, what \nit does ismanipulate formal symbols. The fact that the programmer and theinterpreter of the computer output \nuse the symbols to stand for objectsin the world is totally beyond the scope of the computer. The computer,to \nrepeat, has a syntax but no semantics. Thus, if you type into thecomputer '2 plus 2 equals?\" it will type out '-4.\" \nBut it has no ideathat -4\" means 4 or that it means anything at all. And the point is notthat it lacks some \nsecond-order information about the interpretation ofits first- order symbols, but rather that its first-order \nsymbols don'thave any interpretations as far as the computer is concerned. All thecomputer has is more \nsymbols. \nThe introduction of the notion of \"information processing\" thereforeproduces a dilemma: either we construe the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":9,"to":18}}}}],["ba0dc9ea-67f3-489a-80b8-5cfe001120f8",{"pageContent":"symbols. \nThe introduction of the notion of \"information processing\" thereforeproduces a dilemma: either we construe the \nnotion of \"informationprocessing\" in such a way that it implies intentionality as part of theprocess or we don't. If \nthe former, then the programmed computer doesnot do information processing, it only manipulates formal \nsymbols. Ifthe latter, then, though the computer does information processing, itis only doing so in the sense in \nwhich adding machines, typewriters,stomachs, thermostats, rainstorms, and hurricanes do information\nprocessing; namely, they have a level of description at which we candescribe them as taking information in at \none end, transforming it, andproducing information as output. But in this case it is up to outsideobservers to \ninterpret the input and output as information in theordinary sense. And no similarity is established between the \ncomputerand the brain in terms of any similarity of information processing.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":17,"to":26}}}}],["5a3ebc1b-5eb0-4176-83b4-6135841488e7",{"pageContent":"interpret the input and output as information in theordinary sense. And no similarity is established between the \ncomputerand the brain in terms of any similarity of information processing.\nSecond, in much of AI there is a residual behaviorism oroperationalism. Since appropriately programmed \ncomputers can haveinput-output patterns similar to those of human beings, we are temptedto postulate mental \nstates in the computer similar to human mentalstates. But once we see that it is both conceptually and \nempiricallypossible for a system to have human capacities in some realm withouthaving any intentionality at all, \nwe should be able to overcome thisimpulse. My desk adding machine has calculating capacities, but no\nintentionality, and in this paper I have tried to show that a systemcould have input and output capabilities that \nduplicated those of anative Chinese speaker and still not understand Chinese, regardless ofhow it was","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":25,"to":33}}}}],["7062863f-514b-4769-802e-19bb106b85c0",{"pageContent":"duplicated those of anative Chinese speaker and still not understand Chinese, regardless ofhow it was \nprogrammed. The Turing test is typical of the tradition inbeing unashamedly behavioristic and operationalistic, \nand I believethat if AI workers totally repudiated behaviorism and operationalismmuch of the confusion \nbetween simulation and duplication would beeliminated.\nThird, this residual operationalism is joined to a residual form ofdualism; indeed strong AI only makes sense \ngiven the dualisticassumption that, where the mind is concerned, the brain doesn't matter.In strong AI (and in \nfunctionalism, as well) what matters are programs,and programs are independent of their realization in \nmachines; indeed,as far as AI is concerned, the same program could be realized by anelectronic machine, a \nCartesian mental substance, or a Hegelian worldspirit. The single most surprising discovery that I have made in","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":33,"to":41}}}}],["bdbfa50c-20c2-42ab-8bc2-7fb3280d4466",{"pageContent":"Cartesian mental substance, or a Hegelian worldspirit. The single most surprising discovery that I have made in\ndiscussing these issues is that many AI workers are quite shocked by myidea that actual human mental \nphenomena might be dependent on actualphysical/chemical properties of actual human brains.\nBut if you think about it a minute you can see that I should not havebeen surprised; for unless you accept some \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 13 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":41,"to":46}}}}],["8a7bd082-9732-43b5-8ad1-5e2f47d87f0a",{"pageContent":"form of dualism, the strongAI project hasn't got a chance. The project is to reproduce and explainthe mental \nby designing programs, but unless the mind is not onlyconceptually but empirically independent of the brain you \ncouldn'tcarry out the project, for the program is completely independent of anyrealization. Unless you believe \nthat the mind is separable from thebrain both conceptually and empirically -- dualism in a strong form --you \ncannot hope to reproduce the mental by writing and running programssince programs must be independent of \nbrains or any other particularforms of instantiation. If mental operations consist in computationaloperations on \nformal symbols, then it follows that they have nointeresting connection with the brain; the only connection \nwould bethat the brain just happens to be one of the indefinitely many types ofmachines capable of instantiating \nthe program.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":1,"to":9}}}}],["c35824bc-c925-428f-96ad-f8143272ea4c",{"pageContent":"would bethat the brain just happens to be one of the indefinitely many types ofmachines capable of instantiating \nthe program. \nThis form of dualism is not the traditional Cartesian variety thatclaims there are two sorts of substances, but it \nis Cartesian in thesense that it insists that what is specifically mental about the mindhas no intrinsic connection \nwith the actual properties of the brain.This underlying dualism is masked from us by the fact that AIliterature \ncontains frequent fulminations against \"dualism'-; what theauthors seem to be unaware of is that their position \npresupposes astrong version of dualism.\n\"Could a machine think?\" My own view is that only a machine couldthink, and indeed only very special kinds \nof machines, namely brainsand machines that had the same causal powers as brains. And that isthe main \nreason strong AI has had little to tell us about thinking,since it has nothing to tell us about machines. By its own","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":8,"to":17}}}}],["894e13b3-2fe0-4362-92ae-24cabbaa8a5d",{"pageContent":"reason strong AI has had little to tell us about thinking,since it has nothing to tell us about machines. By its own \ndefinition,it is about programs, and programs are not machines. Whatever elseintentionality is, it is a biological \nphenomenon, and it is as likelyto be as causally dependent on the specific biochemistry of its originsas \nlactation, photosynthesis, or any other biological phenomena. No onewould suppose that we could produce \nmilk and sugar by running acomputer simulation of the formal sequences in lactation andphotosynthesis, but \nwhere the mind is concerned many people arewilling to believe in such a miracle because of a deep and abiding\ndualism: the mind they suppose is a matter of formal processes and isindependent of quite specific material \ncauses in the way that milk andsugar are not.\nIn defense of this dualism the hope is often expressed that the brainis a digital computer (early computers, by","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":17,"to":25}}}}],["75a092fc-a0d4-48a4-b411-c7d2fc8ba4d1",{"pageContent":"causes in the way that milk andsugar are not.\nIn defense of this dualism the hope is often expressed that the brainis a digital computer (early computers, by \nthe way, were often called\"electronic brains\"). But that is no help. Of course the brain is adigital computer. \nSince everything is a digital computer, brains aretoo. The point is that the brain's causal capacity to produce\nintentionality cannot consist in its instantiating a computer program,since for any program you like it is possible \nfor something toinstantiate that program and still not have any mental states. Whateverit is that the brain does \nto produce intentionality, it cannot consistin instantiating a program since no program, by itself, is sufficientfor \nintentionality.\nACKNOWLEDGMENT\nI am indebted to a rather large number of people fordiscussion of these matters and for their patient attempts \nto overcomemy ignorance of artificial intelligence. I would especially like tothank Ned Block, Hubert Dreyfus,","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":24,"to":34}}}}],["8497a381-c244-4b63-8cdd-b036f788b54e",{"pageContent":"to overcomemy ignorance of artificial intelligence. I would especially like tothank Ned Block, Hubert Dreyfus, \nJohn Haugeland, Roger Schank, RobertWilensky, and Terry Winograd.\nNOTES\n1.I am not, of course, saying that Schank himself is committed to theseclaims.\n2.Also, \"understanding\" implies both the possession of mental(intentional) states and the truth (validity, \nsuccess) of these statesFor the purposes of this discussion we are concerned only with thepossession of \nthe states.\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 14 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":34,"to":42}}}}],["429cec84-50e4-4088-9b9f-fbe1ab48330d",{"pageContent":"3.Intentionality is by definition that feature of certain mentalstates by which they are directed at or about \nobjects and states ofaffairs in the world. Thus, beliefs, desires, and intentions areintentional states; \nundirected forms of anxiety and depression are not.For further discussion see Searle (1979c).\nREFERENCES\nAnderson, J. (1980) Cognitive units. Paper presented at the Society forPhilosophy and Psychology, Ann \nArbor, Mich. [RCS]\nBlock, N. J. (1978) Troubles with functionalism. In: Minnesota studiesin the philosophy of science, vol. 9, ed. \nC. W. Savage, Minneapolis:University of Minnesota Press. [NB, WGL]\n(forthcoming) Psychologism and behaviorism. Philosophical Review. [NB,WGL]\nBower, G. H.; Black, J. B., & Turner, T. J. (1979) Scripts in textcomprehension and memory. Cognition \nPsychology 11:177-220. [RCS]\nCarroll, C. W. (1975) The great chess automaton. New York: Dover. [RP]\nCummins, R. (1977) Programs in the explanation of behavior. Philosophyof Science 44: 269-87. UCM]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":15,"lines":{"from":1,"to":13}}}}],["ab285cd2-1f75-4842-b526-b2aa63a8742f",{"pageContent":"Psychology 11:177-220. [RCS]\nCarroll, C. W. (1975) The great chess automaton. New York: Dover. [RP]\nCummins, R. (1977) Programs in the explanation of behavior. Philosophyof Science 44: 269-87. UCM]\nDennett, D. C. (1969) Content and consciousness. London: Routledge &Kegan Paul. [DD,TN]\n______. (1971) Intentional systems Journal of Philosophy 68: 87-106.[TN]\n______. (1972) Reply to Arbib and Gunderson. Paper presented at theEastern Division meeting of the \nAmerican Philosophical Association.Boston, Mass. [TN]\n______. (1975) Why the law of effect won't go away. Journal for theTheory of Social Behavior 5:169-87. \n[NB]\n______. (1978) Brainstorms. Montgomery, Vt,: Bradford Books. [DD, AS]\nEccles, J. C. (1978) A critical appraisal of brain-mind theories. In:Cerebral correlates of conscious \nexperiences, ed. P. A. Buser and A.Rougeul-Buser, pp. 347 55. Amsterdam: North Holland. [JCE]\n______. (1979) The human mystery. Heidelberg: Springer Verlag. UCE]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":15,"lines":{"from":11,"to":23}}}}],["2bc44059-def0-410b-892a-c05fc1fe267a",{"pageContent":"experiences, ed. P. A. Buser and A.Rougeul-Buser, pp. 347 55. Amsterdam: North Holland. [JCE]\n______. (1979) The human mystery. Heidelberg: Springer Verlag. UCE]\nFodor, J. A. (1968) The appeal to tacit knowledge in psychologicalexplanation. Journal of Philoso phy 65: \n627-40. [NB]\n______. (1980) Methodological solipsism considered as a researchstrategy in cognitive psychology. The \nBehavioral and Brain S^ciences3:1. [NB, WGL, WES]\nFreud, S. (1895) Project for a scientific psychology. In: The standardedition of the complete psychological \nworks of Sigmund Freud, vol. 1,ed. J. Strachey. London: Hogarth Press, 1966. UCM]\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 15 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":15,"lines":{"from":22,"to":31}}}}],["5fa4aacb-b7e3-4ba2-bcb2-5a2025dea1dd",{"pageContent":"Frey, P. W. (1977) An introduction to computer chess. In: Chess skill inman and machine, ed. P. W. Frey. \nNew York, Heidelberg, Berlin:Springer Verlag. [RP]\nFryer, D. M. & Marshall, J. C. (1979) The motives of Jacques deVaucanson. Technology and Culture 20: \n257-69. [JCM]\nGibson, J. J. (1976) The senses considered as perceptual systems.Boston: Houghton Mifflin. [TN]\n______. (1967) New reasons for realism. Synthese 17: 162-72. [TN]\n______. (1972) A theory of direct visual perception. In: The psychologyof knowing ed. S. R. Royce & W. \nW. Rozeboom. New York: Gordon &Breach. [TN]\nGraesser, A. C.; Gordon, S. E.; & Sawyer, J. D. (1979) Recognitionmemory for typical and atypical actions \nin scripted activities: testsfor a script pointer and tag hypotheses. Journal of Verbal Learningand Verbal \nBehavior 1: 319-32. [RCS]\nCruendel, J. (1980). Scripts and stories: a study of children's eventnarratives. Ph.D. dissertation, Yale \nUniversity. [RCS]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":16,"lines":{"from":1,"to":13}}}}],["aea209a9-6d45-4f12-886f-183a636ce345",{"pageContent":"Behavior 1: 319-32. [RCS]\nCruendel, J. (1980). Scripts and stories: a study of children's eventnarratives. Ph.D. dissertation, Yale \nUniversity. [RCS]\nHanson, N. R. (1969) Perception and discovery. San Francisco: Freeman,Cooper. [DOW]\nHayes, P. J. (1977) In defence of logic. In: Proceedings of the 5thinternational joint conference on artificial \nintelligence, ed. R. Reddy.Cambridge, Mass.: M.l.T. Press. [WES]\nHobbes, T. (1651) Leviathan. London: Willis. UCM]\nHofstadter, D. R. (1979) Goedel, Escher, Bach. New York: BasicBooks. [DOW]\nHouseholder, F. W. (1962) On the uniqueness of semantic mapping. Word18: 173-85. UCM]\nHuxley, T. H. (1874) On the hypothesis that animals are automata andits history. In: Collected Essays, vol. 1. \nLondon: Macmillan, 1893.UCM]\nKolers, P. A. & Smythe, W. E. (1979) Images, symbols, and skills.Canadian Journal of Psychology 33: 158 \n84. [WES]\nKosslyn, S. M. & Shwartz, S. P. (1977) A simulation of visual imagery.Cognitive Science 1: 265-95. [WES]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":16,"lines":{"from":11,"to":24}}}}],["0e406171-89a0-411f-a911-3ffce79b5c65",{"pageContent":"84. [WES]\nKosslyn, S. M. & Shwartz, S. P. (1977) A simulation of visual imagery.Cognitive Science 1: 265-95. [WES]\nLenneberg, E. H. (1975) A neuropsychological comparison between man,chimpanzee\nand monkey. Neuropsychologia 13: 125. [JCE]\nLibet, B. (1973) Electrical stimulation of cortex in human subjects andconscious sensory aspects. In: \nHandbook of sensory physiology, vol. 11,ed. A. Iggo, pp. 74S 90. New York: Springer-Verlag. [BL]\nLibet, B., Wright, E. W., Jr., Feinstein, B., and Pearl, D. K. (1979)Subjective referral of the timing for a \n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 16 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":16,"lines":{"from":23,"to":31}}}}],["7b31acda-b7cf-4351-8e43-3b297645f1b5",{"pageContent":"conscious sensory experience: afunctional role for the somatosensory specific projection system inman. Brain \n102:191222. [BL]\nLonguet-Higgins, H. C. (1979) The perception of music. Proceedings ofthe Royal Society of London B \n205:307-22. [JCM]\nLucas, J. R. (1961) Minds, machines, and Godel. Philosophy 36:112127.[DRH]\nLycan, W. G. (forthcoming) Form, function, and feel. Journal ofPhilosophy [NB, WGL]\nMcCarthy, J. (1979) Ascribing mental qualities to machines. In:Philosophical perspectives in artificial \nintelligence, ed. M. Ringle.Atlantic Highlands, N.J.: Humanities Press. UM, JRS]\nMarr, D. & Poggio, T. (1979) A computational theory of human stereovision. Proceedings of the Royal \nSociety of London B 204:301-28. UCM]\nMarshall, J. C. (1971) Can humans talk? In: Biological and socialfactors in psycholinguistics, ed. J. Morton. \nLondon: Logos Press. [JCM]\n______. (1977) Minds, machines and metaphors. Social Studies of Science7:47588. [JCM]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":17,"lines":{"from":1,"to":13}}}}],["07dad2dd-f32a-4695-a08d-a138a298504a",{"pageContent":"London: Logos Press. [JCM]\n______. (1977) Minds, machines and metaphors. Social Studies of Science7:47588. [JCM]\nMaxwell, G. (1976) Scientific results and the mind-brain issue. In:Consciousness and the brain, ed. G. G. \nGlobus, G. Maxwell, & 1.Savodnik. New York: Plenum Press. [GM]\n______. (1978) Rigid designators and mind-brain identity. In:Perception and cognition: Issues in the \nfoundations of psychology,Minnesota Studies in the Philosophy of Science, vol. 9, ed. C. W.Savage. \nMinneapolis: University of Minnesota Press. [GM]\nMersenne, M. (1636) Harmonie universelle Paris: Le Gras. UCM]\nMoor, J. H. (1978) Three myths of computer science. British Journal ofthe Philosophy of Science 29:213-22. \nUCM]\nNagel, T. (1974) What is it like to be a bat? Philosophical Review83:43550. [GM]\nNatsoulas, T. (1974) The subjective, experiential element inperception. Psychological Bulletin 81:611-31. \n[TN]\n______. (1977) On perceptual aboutness. Behaviorism 5:75-97. [TN]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":17,"lines":{"from":12,"to":25}}}}],["dd801b74-f2b7-4731-a2e1-8b4ae16a8683",{"pageContent":"Natsoulas, T. (1974) The subjective, experiential element inperception. Psychological Bulletin 81:611-31. \n[TN]\n______. (1977) On perceptual aboutness. Behaviorism 5:75-97. [TN]\n______. (1978a) Haugeland's first hurdle. Behavioral and Brain Sciences1:243. [TN]\n______. (1979b) Residual subjectivity. American Psychologist 33:269-83.[TN]\n______. (1980) Dimensions of perceptual awareness. PsychologyDepartment, University of California, Davis. \nUnpublished manuscript.[TN]\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 17 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":17,"lines":{"from":23,"to":31}}}}],["b126406c-df4d-4315-bf5a-ce593378bb12",{"pageContent":"Nelson, K. & Gruendel, J. (1978) From person episode to social script:two dimensions in the development of \nevent knowledge. Paper presentedat the biennial meeting of the Society for Research in ChildDevelopment, \nSan Francisco. [RCS]\nNewell, A. (1973) Production systems: models of control structures. In:Visual information processing, ed. W. \nC. Chase. New York: AcademicPress. [WES]\n( 1979) Physical symbol systems. Lecture t the La Jolla Conference onCognitive Science. URS]\n______. (1980) Harpy, production systems, and human cognition. In:Perception and production of fluent \nspeech, ed. R. Cole. Hillsdale,N.J.: Erlbaum Press. [WES]\nNewell, A. & Simon, H. A. (1963) GPS, a program that simulates humanthought. In: Computers and thought, \ned. A. Feigenbaum & V. Feldman,pp. 279-93. New York: McGraw Hill. JRS]\nPanofsky, E. (1954) Galileo as a critic of the arts. The Hague:Martinus Nijhoff. UCM]\nPopper, K. R. & Eccles, J. C. (1977) The self and its brain.Heidelberg: Springer-Verlag. UCE, GM]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":18,"lines":{"from":1,"to":12}}}}],["cc6f6e10-522f-41ea-8195-eb8685fe9a92",{"pageContent":"Panofsky, E. (1954) Galileo as a critic of the arts. The Hague:Martinus Nijhoff. UCM]\nPopper, K. R. & Eccles, J. C. (1977) The self and its brain.Heidelberg: Springer-Verlag. UCE, GM]\nPutnam, H. (1960) Minds and machines. In Dimensions of mind, ed. S.Hook, pp. 138 64. New York: Collier. \n[MR, RR]\n______. (1975a) The meaning of ''meaning.\" In: Mind, language andreality Cambridge University Press. [NB, \nWGL]\n______. (1975b) The nature of mental states. In: Mind, language andreality Cambridge: Cambridge University \nPress. [NB]\n______. (1975c) Philosophy and our mental life In: Mind, language andreality Cambridge: Cambridge \nUniversity Press. [MM]\nPylyshyn, Z. W. (1980a) Computation and cognition: issues in thefoundations of cognitive science. Behavioral \nand Brain Sciences 3.[JRS, WES]\n______. (1980b) Cognitive representation and the process-architecturedistinction. Behavioral and Brain \nSciences [ZWP]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":18,"lines":{"from":11,"to":24}}}}],["b226f843-24e8-4a48-aacf-2f4610f8d0e0",{"pageContent":"and Brain Sciences 3.[JRS, WES]\n______. (1980b) Cognitive representation and the process-architecturedistinction. Behavioral and Brain \nSciences [ZWP]\nRussell, B. (1948) Human knowledge: its scope and limits New York:Simon and Schuster. [GM]\nSchank, R. C. & Abelson, R. P. (1977) Scripts, plans, goals, andunderstanding Hillsdale, N.J.: Lawrence \nErlbaum Press. [RCS, JRS]\nSearle, J. R. (1979a) Intentionality and the use of language. In:Meaning and use, ed. A. Margalit. Dordrecht: \nReidel. [TN, JRS]\n______. (1979b) The intentionality of intention and action. Inquiry22:25380. [TN, JRS]\n______. (1979c) What is an intentional state? Mind 88:74-92. UH, GM,TN, JRS]\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 18 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":18,"lines":{"from":22,"to":33}}}}],["22b8873e-1b9a-48c3-946a-2f40f4157442",{"pageContent":"Sherrington, C. S. (1950) Introductory. In: The physical basis of mind,ed. P. Laslett, Oxford: Basil Blackwell. \n[JCE]\nSlate, J. S. & Atkin, L. R. (1977) CHESS 4.5 - the NorthwesternUniversity chess program. In: Chess skill in \nman and machine, ed. P. W.Frey. New York, Heidelberg, Berlin: Springer Verlag. Sloman, A. (1978)The \ncomputer resolution in phylosophy Harvester Press and HumanitiesPress. [AS]\n______. (1979) The primacy of non-communicative language. In: Theanalysis of meaning (informatics s)> ed. \nM. McCafferty & K. Gray.London: ASLIB and British Computer Society. [AS]\nSmith, E. E.; Adams, N.; & Schorr, D. (1978) Fact retrieval and theparadox of interference. Cognition \nPsychology 10:438-64. [RCS]\nSmythe, W. E. (1979) The analogical/propositional debate about mentalrep representation: a Goodmanian \nanalysis Paper presented at the 5th annualmeeting of the Society for Philosophy and Psychology, New York \nCity.[WES]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":19,"lines":{"from":1,"to":12}}}}],["2df116f4-f7f0-4441-8a42-7f9bd8b7679a",{"pageContent":"analysis Paper presented at the 5th annualmeeting of the Society for Philosophy and Psychology, New York \nCity.[WES]\nSperry, R. W. (1969) A modified concept of consciousness. PsychologicalReview 76:532-36. [TN]\n______. (1970) An objective approach to subjective experience: furtherexplanation of a hypothesis. \nPsychological Review 77:585-90. [TN]\n______. (1976) Mental phenomena as causal determinants in brainfunction. In: Consciousness and the brain, \ned. G. G. Globus, G.Maxwell, & 1. Savodnik. New York: Plenum Press. [TN]\nStich, S. P. (in preparation) On the ascription of content. In:Entertaining thoughts, ed. A. Woodfield. [WGL]\nThorne, J. P. (1968) A computer model for the perception of syntacticstructure. Proceedings of the Royal \nSociety of London B 171:37786.UCM]\nTuring, A. M. (1964) Computing machinery and intelligence. In: Mindsand machines, ed. A. R. Anderson, \npp.4-30. Englewood Cliffs, N.J.:Prentice Hall. [MR]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":19,"lines":{"from":11,"to":22}}}}],["b0e2ccac-876c-4900-a0b5-bf9d70ed6d4d",{"pageContent":"Society of London B 171:37786.UCM]\nTuring, A. M. (1964) Computing machinery and intelligence. In: Mindsand machines, ed. A. R. Anderson, \npp.4-30. Englewood Cliffs, N.J.:Prentice Hall. [MR]\nWeizenbaum, J. (1965) Eliza - a computer program for the study ofnatural language communication between \nman and machine. Communicationof the Association for Computing Machinery 9:36 45. [JRS]\n( 1976) Computer power and human reason San Francisco: W. H. Freeman.URS]\nWinograd, T. (1973) A procedural model of language understanding. In:Computer models of thought and \nlanguage, ed. R. Schank & K. Colby. SanFrancisco: W. H. Freeman. [JRS]\nWinston, P. H. (1977) Artificial intelligence Reading, Mass. Addison-Wesley; JRS]\nWoodruff, G. & Premack, D. (1979) Intentional communication in thechimpanzee: the development of \ndeception. Cognition 7:333-62. [JCM]\n7/14/03 6:14 PMMinds, Brains, and Programs\nPage 19 of 19http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":19,"lines":{"from":20,"to":32}}}}]],{"0":"ab6cdb13-45c2-46a3-ae24-29ad082d3437","1":"2ab32053-d13d-4ad6-952c-076009f95ebb","2":"28ff6c49-8328-49cd-930a-ae94b69a8741","3":"a324024a-d4ca-4b51-8d55-bc05e58ccf98","4":"4b3cf54e-24ff-408a-a6dd-4bc5b7c79bb3","5":"47621017-966a-4dd7-a773-63b638ec65e6","6":"dda68bb6-20f7-4fb7-8008-48b2676f7a8a","7":"da6b404c-0e92-4215-bce3-665a3d43539e","8":"ce47cbf3-6163-43c6-a567-1857f878a57c","9":"2a5b89fc-c8e8-414d-bfcb-76f9b14edcd8","10":"7c8da1d6-785a-4706-a73e-b87753c47a55","11":"92ad219d-c506-416f-9718-b38beb655f5c","12":"2c9a41a7-5456-48e9-b817-e015c9119f36","13":"672a729a-eafd-46f7-8e31-5be4034de844","14":"f3338716-67d2-4b25-be68-c1b560942c77","15":"5daa088d-28ef-42f9-84c5-1060ac0ec989","16":"b77f4bf3-7062-4a14-94bc-c1e3dc9a49ba","17":"4d5546b1-104e-4261-8920-06fe0909c03a","18":"28610a06-4a88-4016-af5a-1b955616cc3f","19":"5263e6e0-56f1-46b5-8477-93c274e218a2","20":"34bb5413-b87a-4ffa-976e-a75f42806c70","21":"9eee4357-fa3b-4a14-a1da-e86f6dd5ce80","22":"ede5c55d-59a1-44ee-a6e7-7b1d443fa09e","23":"31102c9c-3273-4d81-b569-8056d38b4670","24":"c4ab419c-371a-4788-904e-076c4aeffadd","25":"4728e367-42a1-4751-b211-f2b0c856e428","26":"b20853db-d6fd-4a2c-bfa7-b9a2eb0391cf","27":"040773c6-bd00-484e-b158-7f291faa135d","28":"52c67943-895d-46e9-ae30-b15c7a14f041","29":"89957bb3-d95f-4230-bc6c-c8e71ce2e4dc","30":"778a0177-d913-4663-b9c4-ea3e1bfa77d3","31":"9819da5f-3ad0-497d-861d-582fd96d3a0d","32":"f5b4b7d7-974f-48eb-a217-a09ef58f855e","33":"35a4ffe2-6eca-4de8-bc8c-a980f1b96661","34":"ed322b70-a2fc-414f-b684-758c53d079d5","35":"a84371ad-393c-49d0-9a6e-2f1af541678c","36":"7d1c8bd2-d573-4b00-b0bd-c0579ae76f97","37":"4ddc14ea-3fca-4e7f-9cef-d8e551a75eb2","38":"8b3b96f2-5647-47f0-b193-70c9c9b5b4c4","39":"08741ba6-8dba-41be-8110-94452e26c0b3","40":"2c0cb67c-2b12-4cdd-9256-5433e9177f78","41":"918d5d8a-d3ac-4c1b-82a5-db6b3b4cfcf2","42":"812917fe-21e6-4ed2-aa53-476db0922377","43":"137ee5f4-ba4c-4d25-ad74-b0dde8e02fad","44":"a6a7b3e1-200d-46f0-8d8d-edf29f5408ed","45":"d73827b4-6a2a-4c30-b77b-3d195aaa4539","46":"5af78d11-3f5b-4a27-b7bc-2e00d2c8e75c","47":"ad9b1517-52a1-4780-a4d3-4d18cd8adef8","48":"9955b27b-fab0-49d4-bca5-e7593eebc235","49":"7d6abb4c-769c-4ac4-a674-acc96719e175","50":"6262b839-0392-43a4-b4d5-7d26ec9516f1","51":"639b6870-2fc3-4840-a9d8-2db3e0395335","52":"a7c0624e-72dd-48e5-b54f-d829604c5308","53":"a7b03d5c-bbca-408f-8f0a-db8c357c3bef","54":"dc2194c9-0555-41f6-bc4f-5d53c23f083e","55":"64de6418-20a8-4ecd-9522-0a033b9cc9c1","56":"486b1f9f-9a85-437b-a720-c80e3baeb61f","57":"1de32464-8408-43fb-964a-dc6882391744","58":"57584fc1-d11b-4502-938d-7e669fe6025f","59":"cfc2b879-29bc-4ac4-a857-fe3b0ca35b3d","60":"e1c32849-fe62-4a58-8121-f5fdab3f45a0","61":"56540f53-8bef-404e-8ab3-61d6b173747b","62":"0b2e9624-3e25-440d-8437-b2b2b9bd0db2","63":"6d41fbed-77f8-4245-ba3f-d24d883ca66f","64":"9a0c0292-b8ee-4c65-ab52-3c33d99e26e7","65":"863332ac-7593-4614-b5ae-8f755e16d3de","66":"587b37b9-c51b-4229-84da-931479c08953","67":"e748e369-0b84-4ff6-a728-b1ede0b41ef8","68":"845877d4-9c83-4d36-be81-cb774f268879","69":"ba0dc9ea-67f3-489a-80b8-5cfe001120f8","70":"5a3ebc1b-5eb0-4176-83b4-6135841488e7","71":"7062863f-514b-4769-802e-19bb106b85c0","72":"bdbfa50c-20c2-42ab-8bc2-7fb3280d4466","73":"8a7bd082-9732-43b5-8ad1-5e2f47d87f0a","74":"c35824bc-c925-428f-96ad-f8143272ea4c","75":"894e13b3-2fe0-4362-92ae-24cabbaa8a5d","76":"75a092fc-a0d4-48a4-b411-c7d2fc8ba4d1","77":"8497a381-c244-4b63-8cdd-b036f788b54e","78":"429cec84-50e4-4088-9b9f-fbe1ab48330d","79":"ab285cd2-1f75-4842-b526-b2aa63a8742f","80":"2bc44059-def0-410b-892a-c05fc1fe267a","81":"5fa4aacb-b7e3-4ba2-bcb2-5a2025dea1dd","82":"aea209a9-6d45-4f12-886f-183a636ce345","83":"0e406171-89a0-411f-a911-3ffce79b5c65","84":"7b31acda-b7cf-4351-8e43-3b297645f1b5","85":"07dad2dd-f32a-4695-a08d-a138a298504a","86":"dd801b74-f2b7-4731-a2e1-8b4ae16a8683","87":"b126406c-df4d-4315-bf5a-ce593378bb12","88":"cc6f6e10-522f-41ea-8195-eb8685fe9a92","89":"b226f843-24e8-4a48-aacf-2f4610f8d0e0","90":"22b8873e-1b9a-48c3-946a-2f40f4157442","91":"2df116f4-f7f0-4441-8a42-7f9bd8b7679a","92":"b0e2ccac-876c-4900-a0b5-bf9d70ed6d4d"}]